{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fce22a-8b67-4580-a0a4-81da7fdab805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz as sv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525ee82-1d39-4641-991a-39d633540dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IQR_Rejection(data_frame, column_name):\n",
    "    q1 = data_frame[column_name].quantile(0.25)\n",
    "    q3 = data_frame[column_name].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    fence_low  = q1 - 1.5*iqr\n",
    "    fence_high = q3 + 1.5*iqr\n",
    "    df_out = data_frame.loc[(data_frame[column_name] > fence_low) & (data_frame[column_name] < fence_high)]\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83239b1d-eda1-4a95-ae1f-1856f537ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_Outliers(df):\n",
    "    filt_df = IQR_Rejection(IQR_Rejection(df, 'Total_Amt_Outflow_L3M'), 'Total_Amt_Inflow_L3M')\n",
    "    return filt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d52857-35d9-4fc0-ab80-b9945e0c8de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_cols(df):\n",
    "    for (columnName, columnData) in filt_df.iteritems():\n",
    "        if (columnData.unique().size > 3) & ((columnData == 0).mean() > 0.5):\n",
    "            filt_df[columnName] = np.where(columnData == 0, 0, 1)\n",
    "    return filt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455362c2-4a40-4e1a-9074-7bc721421cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_path, keep_outliers=False, binarize_cols=True, split_structure=True):\n",
    "    # Read in the data frame using Pandas\n",
    "    df = pd.read_csv(data_path, sep='|')\n",
    "    df = df.drop(['ClientIdentifier', 'Behaviour_Date_Key'], axis=1)\n",
    "    df = df.drop(['Instalment_Amt_All', 'Current_Balance_All', 'ALL_Max_Delq_Ever'], axis=1)\n",
    "    df['Has_Deed'] = df['Has_Deed'].map({'Y': 1, 'N': 0})\n",
    "    df = df.dropna()\n",
    "    behaviours = df.BehaviourType.unique()\n",
    "    behaviours.sort()\n",
    "    \n",
    "    if split_structure:\n",
    "        frame_storage = []\n",
    "        for i in range(0, len(behaviours), 2):\n",
    "            new_frame = df[df['BehaviourType'] == behaviours[i]]\n",
    "            new_not_frame = df[df['BehaviourType'] == behaviours[i+1]]\n",
    "            frame = pd.concat([new_frame, new_not_frame])\n",
    "            frame_storage.append(frame)\n",
    "\n",
    "        newFrames = {'APP': frame_storage[0],\n",
    "                     'BANK': frame_storage[1],\n",
    "                     'CARD': frame_storage[2],\n",
    "                     'CREDIT': frame_storage[3],\n",
    "                     'DEBIT': frame_storage[4],\n",
    "                     'FIN_ED': frame_storage[5],\n",
    "                     'LOAN': frame_storage[6],\n",
    "                     'SAVE': frame_storage[7],\n",
    "                     'VIRT_CARD': frame_storage[8]}\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "    if keep_outliers == False:\n",
    "        for key, value in newFrames.items():\n",
    "            newFrames[key] = filter_Outliers(value)\n",
    "    if binarize_cols == True:\n",
    "        for key, value in newFrames.items():\n",
    "            newFrames[key] = binarize_cols(value)\n",
    "    \n",
    "    return newFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d966f-e086-4baf-8cd1-64ccd8c1c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COPY\n",
    "def prepare_data_sample(data_path, keep_outliers=False, binarize_cols=True, split_structure=True):\n",
    "    # Read in the data frame using Pandas\n",
    "    df = pd.read_csv(data_path, sep='|')\n",
    "    df = df.drop(['ClientIdentifier', 'Behaviour_Date_Key'], axis=1)\n",
    "    df = df.drop(['Instalment_Amt_All', 'Current_Balance_All', 'ALL_Max_Delq_Ever'], axis=1)\n",
    "    df['Has_Deed'] = df['Has_Deed'].map({'Y': 1, 'N': 0})\n",
    "    df = df.dropna()\n",
    "    behaviours = df.BehaviourType.unique()\n",
    "    behaviours.sort()\n",
    "    \n",
    "    if split_structure:\n",
    "        frame_storage = []\n",
    "        for i in range(0, len(behaviours), 2):\n",
    "            new_frame = df[df['BehaviourType'] == behaviours[i]]\n",
    "            new_not_frame = df[df['BehaviourType'] == behaviours[i+1]].sample(frac=0.05)\n",
    "            frame = pd.concat([new_frame, new_not_frame])\n",
    "            frame_storage.append(frame)\n",
    "\n",
    "        newFrames = {'APP': frame_storage[0],\n",
    "                     'BANK': frame_storage[1],\n",
    "                     'CARD': frame_storage[2],\n",
    "                     'CREDIT': frame_storage[3],\n",
    "                     'DEBIT': frame_storage[4],\n",
    "                     'FIN_ED': frame_storage[5],\n",
    "                     'LOAN': frame_storage[6],\n",
    "                     'SAVE': frame_storage[7],\n",
    "                     'VIRT_CARD': frame_storage[8]}\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "    if keep_outliers == False:\n",
    "        for key, value in newFrames.items():\n",
    "            newFrames[key] = filter_Outliers(value)\n",
    "    if binarize_cols == True:\n",
    "        for key, value in newFrames.items():\n",
    "            newFrames[key] = binarize_cols(value)\n",
    "    \n",
    "    return newFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d6e8e2-5ead-41d8-8e52-a7b65e0887bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = prepare_data('ClientBehaviourTraining.txt', binarize_cols=False)\n",
    "dfs2 =  prepare_data_sample('ClientBehaviourTraining.txt', binarize_cols=False)\n",
    "#print(dfs['APP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a7a8e-aec3-4257-8c92-936654c1c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarySubset():\n",
    "\n",
    "    _name = None\n",
    "    _df = None\n",
    "    _X_train = None\n",
    "    _X_test = None\n",
    "    _y_train = None\n",
    "    _y_test = None\n",
    "    _target = None\n",
    "    _scaled = None\n",
    "    \n",
    "    _pca_data = None\n",
    "    _pca_trans = None\n",
    "    _pca_cols = None\n",
    "    _pca_suc = False\n",
    "    \n",
    "    _model = None\n",
    "    _predictions = None\n",
    "    _classification_report = None\n",
    "    _roc_curve = None\n",
    "    \n",
    "    def __init__(self, data, name, use_PCA=False):\n",
    "        self._name = name\n",
    "        self._df= data\n",
    "        self._target = self.create_target()\n",
    "        self._scaled = self.scale_df()\n",
    "        if use_PCA:\n",
    "            self.pca_fit_transform(0.9)\n",
    "            self.create_train_test_split(use_PCA)\n",
    "        else:\n",
    "            self.create_train_test_split()\n",
    "\n",
    "    def create_target(self) -> np.array:\n",
    "        target = LabelEncoder().fit_transform(self._df.BehaviourType)\n",
    "        return target\n",
    "    \n",
    "    def scale_df(self) -> pd.DataFrame:\n",
    "        cols = self._df.select_dtypes(include=(\"float64\", \"int64\")).columns\n",
    "        ldscaled = StandardScaler().fit_transform(self._df.select_dtypes(include=(\"float64\", \"int64\")))\n",
    "        ldscaled = pd.DataFrame(ldscaled, columns=cols)\n",
    "        return ldscaled\n",
    "    \n",
    "    def create_train_test_split(self, use_PCA=False):\n",
    "        if use_PCA and self._pca_suc:\n",
    "            self._X_train, self._X_test, self._y_train, self._y_test = train_test_split(self._pca_data, self._target, random_state=21)\n",
    "        else:\n",
    "            self._X_train, self._X_test, self._y_train, self._y_test = train_test_split(self._scaled, self._target, random_state=21)\n",
    "        \n",
    "    def fit_LogisticRegression(self, X, y):\n",
    "        self._model = LogisticRegression(max_iter=10000)\n",
    "        self._model.fit(X, y)\n",
    "    \n",
    "    def fit_ModLogReg(self, X, y):\n",
    "        self._model = LogisticRegression(max_iter=10000, class_weight='balanced', solver='saga')\n",
    "        self._model.fit(X, y)\n",
    "    \n",
    "    def fit_KNN(self, X, y):\n",
    "        self._model = KNeighborsClassifier(n_neighbors=7)\n",
    "        self._model.fit(X, y)\n",
    "    \n",
    "    def fit_dt(self, X, y):\n",
    "        self._model = DecisionTreeClassifier(max_depth=None)\n",
    "        self._model.fit(X, y)\n",
    "        \n",
    "    def fit_nb(self, X, y):\n",
    "        self._model = GaussianNB()\n",
    "        self._model.fit(X, y)\n",
    "    \n",
    "    def fit_GB(self, X, y):\n",
    "        self._model = GradientBoostingClassifier()\n",
    "        self._model.fit(X, y)\n",
    "    \n",
    "    def fit_rf(self, X, y):\n",
    "        self._model = RandomForestClassifier(n_estimators = 50, ccp_alpha = 0.01)\n",
    "        self._model.fit(X, y)\n",
    "    \n",
    "    def fit_nn(self, X, y):\n",
    "        self._model = MLPClassifier(activation = 'logistic', solver='sgd', hidden_layer_sizes=(100), random_state=1, learning_rate='adaptive', learning_rate_init=0.9, max_iter=10000)\n",
    "        self._model.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self._predictions = self._model.predict(X)\n",
    "        self.classification_report()\n",
    "        self.roc_curve()\n",
    "    \n",
    "    def classification_report(self):\n",
    "        self._classification_report = classification_report(y_true=self._y_test, y_pred=self._predictions)\n",
    "    \n",
    "    def roc_curve(self):\n",
    "        self._roc_curve = roc_curve(y_true=self._y_test, y_score=self._predictions)\n",
    "    \n",
    "    def add_roc_curve(self, axes=None, ex_name=''):\n",
    "        if axes is None:\n",
    "            metrics.plot_roc_curve(self._model, self._X_test, self._y_test)\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.show()\n",
    "        else:\n",
    "            RocCurveDisplay.from_estimator(self._model, self._X_test, self._y_test, ax=axes, name=self._name+ex_name)\n",
    "    \n",
    "    def print_roc(self):\n",
    "        metrics.plot_roc_curve(self._model, self._X_test, self._y_test)\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()\n",
    "    \n",
    "    def pca_fit_transform(self, explained_var):\n",
    "        '''\n",
    "        INPUT: n in range(0,1) that represents the amount of variance you would like to keep\n",
    "        '''\n",
    "        i = 0\n",
    "        var = 0\n",
    "        cols = list()\n",
    "        while var < explained_var and i < len(self._scaled):\n",
    "            if i != 0: cols.append(f\"PC{i}\")\n",
    "            pca = PCA(n_components=i).fit(self._scaled)\n",
    "            var = np.sum(pca.explained_variance_ratio_)\n",
    "            i = i + 1\n",
    "        if i < len(self._scaled):\n",
    "            print('PCA Complete!')\n",
    "            self._pca_trans = pca\n",
    "            self._pca_data  = pd.DataFrame(pca.transform(self._scaled), columns=cols)\n",
    "            self._pca_cols = cols\n",
    "            self._pca_suc = True\n",
    "        else:\n",
    "            print('PCA Failed')\n",
    "            self._pca_suc = False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7d0eb-05ba-4019-a955-f0623b3df184",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_PCA = False\n",
    "logReg = [BinarySubset(value, key, use_PCA) for key, value in dfs.items()]\n",
    "KNN = [BinarySubset(value, key, use_PCA) for key, value in dfs.items()]\n",
    "DecTree = [BinarySubset(value, key, use_PCA) for key, value in dfs.items()]\n",
    "Bayes = [BinarySubset(value, key, use_PCA) for key, value in dfs.items()]\n",
    "RandFor = [BinarySubset(value, key, use_PCA) for key, value in dfs.items()]\n",
    "NN = [BinarySubset(value, key, use_PCA) for key, value in dfs.items()]\n",
    "GB = [BinarySubset(value, key, use_PCA) for key, value in dfs.items()]\n",
    "modLogReg = [BinarySubset(value, key, use_PCA) for key, value in dfs.items()]\n",
    "modLogRegSamp = [BinarySubset(value, key, use_PCA) for key, value in dfs2.items()]\n",
    "\n",
    "def print_roc(model):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "\n",
    "    for i in model:\n",
    "        i.add_roc_curve(ax)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def print_class_rep():\n",
    "    for i in subsets:\n",
    "        print(i._name+\"\\n\"+i._classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bce2f3-1a78-407f-b4a7-8432a99e27b5",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef0b1ec-f8d0-4ce8-a078-6800b43a5faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = []\n",
    "for i in logReg:\n",
    "    i.fit_LogisticRegression(i._X_train, i._y_train)\n",
    "    i.predict(i._X_test)\n",
    "    lg.append(i)\n",
    "print_roc(logReg)\n",
    "#print_class_rep()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b6ad2-7e4a-43d3-8a25-5f13b5365b53",
   "metadata": {},
   "source": [
    "***KNN Search***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b586410-1cf9-496f-aa38-50531c2948ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = []\n",
    "for i in KNN:\n",
    "    i.fit_KNN(i._X_train, i._y_train)\n",
    "    i.predict(i._X_test)\n",
    "    knn.append(i)\n",
    "print_roc(KNN)\n",
    "#print_class_rep()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5de867a-4d19-48d7-a51a-b08f79d4da12",
   "metadata": {},
   "source": [
    "***Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a6e306-e926-4c5a-a3b3-5626b10aa9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = []\n",
    "for i in DecTree:\n",
    "    i.fit_dt(i._X_train, i._y_train)\n",
    "    i.predict(i._X_test)\n",
    "    dt.append(i)\n",
    "print_roc(DecTree)\n",
    "#print_class_rep()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c41c59-9f39-4f51-9def-48ab09ed91df",
   "metadata": {},
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad433f-685b-4090-aa4e-2202f5c2fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = []\n",
    "for i in Bayes:\n",
    "    i.fit_nb(i._X_train, i._y_train)\n",
    "    i.predict(i._X_test)\n",
    "    nb.append(i)\n",
    "print_roc(Bayes)\n",
    "#print_class_rep()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bae72f-9d65-4309-bf0a-1f6e6b03c186",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d83bd0f-3830-4625-8012-ba001c99804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = []\n",
    "for i in RandFor:\n",
    "    i.fit_rf(i._X_train, i._y_train)\n",
    "    i.predict(i._X_test)\n",
    "    rf.append(i)\n",
    "print_roc(RandFor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445d086e-1029-45b5-842d-613f4788c214",
   "metadata": {},
   "source": [
    "**Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1dce26-3dcd-49b3-aaa9-be2e9b403ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = []\n",
    "for i in NN:\n",
    "    i.fit_nn(i._X_train, i._y_train)\n",
    "    i.predict(i._X_test)\n",
    "    nn.append(i)\n",
    "    print(\"Converged: {}\".format(i))\n",
    "print_roc(NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f734a7-5b7d-485d-bfbe-07368814a50f",
   "metadata": {},
   "source": [
    "**Gradient Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f34f38d-3307-4028-8a65-ad2218b19f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = []\n",
    "for i in GB:\n",
    "    i.fit_GB(i._X_train, i._y_train)\n",
    "    i.predict(i._X_test)\n",
    "    gb.append(i)\n",
    "    print(\"Converged: {}\".format(i))\n",
    "print_roc(GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be1d502-5706-41bd-a455-0ae5f41ce90f",
   "metadata": {},
   "source": [
    "**Modified LogReg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5524a44d-7f9a-487e-b01d-ad0e6ae12672",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlg = []\n",
    "for i in modLogReg:\n",
    "    i.fit_ModLogReg(i._X_train, i._y_train)\n",
    "    i.predict(i._X_test)\n",
    "    mlg.append(i)\n",
    "    print(\"Converged: {}\".format(i))\n",
    "print_roc(modLogReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e948d8-935c-4afe-9112-cd99919450f6",
   "metadata": {},
   "source": [
    "**Modified LogReg Sampled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95d298-8fa2-4ae7-8163-cd6ee7524155",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlgs = []\n",
    "for i in modLogRegSamp:\n",
    "    i.fit_ModLogReg(i._X_train, i._y_train)\n",
    "    i.predict(i._X_test)\n",
    "    mlgs.append(i)\n",
    "    print(\"Converged: {}\".format(i))\n",
    "print_roc(modLogRegSamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647334e7-b010-43f8-a6b6-a2fc9ef7c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(lg)):\n",
    "    fig, ax = plt.subplots()\n",
    "    lg[i].add_roc_curve(axes=ax,ex_name=' LogReg')\n",
    "    knn[i].add_roc_curve(axes=ax,ex_name=' KNN')\n",
    "    dt[i].add_roc_curve(axes=ax, ex_name=' DecTree')\n",
    "    nb[i].add_roc_curve(axes=ax, ex_name=' Bayes')\n",
    "    rf[i].add_roc_curve(axes=ax, ex_name=' RandFor')\n",
    "    if i == 2:\n",
    "        plt.savefig('Card.png')\n",
    "    elif i == 3:\n",
    "        plt.savefig('Credit.png')\n",
    "    gb[i].add_roc_curve(axes=ax, ex_name=' GB')\n",
    "    mlg[i].add_roc_curve(axes=ax, ex_name=' Modified LG')\n",
    "    mlgs[i].add_roc_curve(axes=ax, ex_name=' MLG Sampled')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58065fb-0139-4c3b-a4c7-3b15f6595a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Prune Eval Set:\n",
    "split = True\n",
    "eval_set = prepare_data('ClientBehaviourEvaluation.txt', keep_outliers=True, binarize_cols=False, split_structure=split)\n",
    "\n",
    "if split:\n",
    "    ldscaled ={}\n",
    "    true_vals = {}\n",
    "    for keys, vals in eval_set.items():\n",
    "        start_index = 1\n",
    "        true = pd.get_dummies(eval_set[keys]['BehaviourType'])\n",
    "        true_vals[keys] = true.iloc[:,[1]]\n",
    "\n",
    "        cols = eval_set[keys].select_dtypes(include=(\"float64\", \"int64\")).columns\n",
    "        scale_frame = StandardScaler().fit_transform(eval_set[keys].select_dtypes(include=(\"float64\", \"int64\")))\n",
    "        ldscaled[keys] = pd.DataFrame(scale_frame, columns=cols)\n",
    "else:\n",
    "    true_vals = {}\n",
    "    start_index = 1\n",
    "    true = pd.get_dummies(eval_set['BehaviourType'])\n",
    "    for key, i in zip(keys, range(start_index, 17+start_index, 2)):\n",
    "        true_vals[key] = true.iloc[:,[i]]\n",
    "\n",
    "    cols = eval_set.select_dtypes(include=(\"float64\", \"int64\")).columns\n",
    "    ldscaled = StandardScaler().fit_transform(eval_set.select_dtypes(include=(\"float64\", \"int64\")))\n",
    "    ldscaled = pd.DataFrame(ldscaled, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a602044-8ec6-47ee-bbe9-97d141153180",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys, i in zip(true_vals.keys(), range(len(logReg))):\n",
    "    print('{}:'.format(keys))\n",
    "\n",
    "    if logReg[i]._pca_suc and use_PCA:\n",
    "        score_logreg = balanced_accuracy_score(true_vals[keys], logReg[i]._model.predict(pd.DataFrame(logReg[i]._pca_trans.transform(ldscaled[keys]), columns=logReg[i]._pca_cols)))\n",
    "        recall_logreg = recall_score(true_vals[keys], logReg[i]._model.predict(pd.DataFrame(logReg[i]._pca_trans.transform(ldscaled[keys]), columns=logReg[i]._pca_cols)))\n",
    "    else:\n",
    "        score_logreg = balanced_accuracy_score(true_vals[keys], logReg[i]._model.predict(ldscaled[keys]))\n",
    "        recall_logreg = recall_score(true_vals[keys], logReg[i]._model.predict(ldscaled[keys]))\n",
    "    print(\"\\tLogistic: {:.3f}, {:.3f}\".format(score_logreg, recall_logreg))\n",
    "\n",
    "\n",
    "    if KNN[i]._pca_suc and use_PCA:\n",
    "        score_knn = balanced_accuracy_score(true_vals[keys], KNN[i]._model.predict(pd.DataFrame(KNN[i]._pca_trans.transform(ldscaled[keys]), columns=KNN[i]._pca_cols)))\n",
    "        recall_knn = recall_score(true_vals[keys], KNN[i]._model.predict(pd.DataFrame(KNN[i]._pca_trans.transform(ldscaled[keys]), columns=KNN[i]._pca_cols)))\n",
    "    else:\n",
    "        score_knn = balanced_accuracy_score(true_vals[keys], KNN[i]._model.predict(ldscaled[keys]))\n",
    "        recall_knn = recall_score(true_vals[keys], KNN[i]._model.predict(ldscaled[keys]))\n",
    "    print(\"\\tKNN: {:.3f}, {:.3f}\".format(score_knn, recall_knn))\n",
    "\n",
    "\n",
    "    if DecTree[i]._pca_suc and use_PCA:\n",
    "        score_dt = balanced_accuracy_score(true_vals[keys], DecTree[i]._model.predict(pd.DataFrame(DecTree[i]._pca_trans.transform(ldscaled[keys]), columns=DecTree[i]._pca_cols)))\n",
    "        recall_dt = recall_score(true_vals[keys], DecTree[i]._model.predict(pd.DataFrame(DecTree[i]._pca_trans.transform(ldscaled[keys]), columns=DecTree[i]._pca_cols)))\n",
    "    else:\n",
    "        score_dt = balanced_accuracy_score(true_vals[keys], DecTree[i]._model.predict(ldscaled[keys]))\n",
    "        recall_dt = recall_score(true_vals[keys], DecTree[i]._model.predict(ldscaled[keys]))\n",
    "    print(\"\\tDecision Tree: {:.3f}, {:.3f}\".format(score_dt, recall_dt))\n",
    "\n",
    "\n",
    "    if Bayes[i]._pca_suc and use_PCA:\n",
    "        score_bayes = balanced_accuracy_score(true_vals[keys], Bayes[i]._model.predict(pd.DataFrame(Bayes[i]._pca_trans.transform(ldscaled[keys]), columns=Bayes[i]._pca_cols)))\n",
    "        recall_bayes = recall_score(true_vals[keys], Bayes[i]._model.predict(pd.DataFrame(Bayes[i]._pca_trans.transform(ldscaled[keys]), columns=Bayes[i]._pca_cols)))\n",
    "    else:\n",
    "        score_bayes = balanced_accuracy_score(true_vals[keys], Bayes[i]._model.predict(ldscaled[keys]))\n",
    "        recall_bayes = recall_score(true_vals[keys], Bayes[i]._model.predict(ldscaled[keys]))\n",
    "    print(\"\\tBayes: {:.3f}, {:.3f}\".format(score_bayes, recall_bayes))\n",
    "\n",
    "\n",
    "    if RandFor[i]._pca_suc and use_PCA:\n",
    "        score_rf = balanced_accuracy_score(true_vals[keys], RandFor[i]._model.predict(pd.DataFrame(RandFor[i]._pca_trans.transform(ldscaled[keys]), columns=RandFor[i]._pca_cols)))\n",
    "        recall_rf = recall_score(true_vals[keys], RandFor[i]._model.predict(pd.DataFrame(RandFor[i]._pca_trans.transform(ldscaled[keys]), columns=RandFor[i]._pca_cols)))\n",
    "    else:\n",
    "        score_rf = balanced_accuracy_score(true_vals[keys], RandFor[i]._model.predict(ldscaled[keys]))\n",
    "        recall_rf = recall_score(true_vals[keys], RandFor[i]._model.predict(ldscaled[keys]))\n",
    "    print(\"\\tRandom Forest: {:.3f}, {:.3f}\".format(score_rf, recall_rf))\n",
    "    \n",
    "    if GB[i]._pca_suc and use_PCA:\n",
    "        score_gb = balanced_accuracy_score(true_vals[keys], GB[i]._model.predict(pd.DataFrame(GB[i]._pca_trans.transform(ldscaled[keys]), columns=GB[i]._pca_cols)))\n",
    "        recall_gb = recall_score(true_vals[keys], GB[i]._model.predict(pd.DataFrame(GB[i]._pca_trans.transform(ldscaled[keys]), columns=GB[i]._pca_cols)))\n",
    "    else:\n",
    "        score_gb = balanced_accuracy_score(true_vals[keys], GB[i]._model.predict(ldscaled[keys]))\n",
    "        recall_gb = recall_score(true_vals[keys], GB[i]._model.predict(ldscaled[keys]))\n",
    "    print(\"\\tGradient Boosting: {:.3f}, {:.3f}\".format(score_gb, recall_gb))\n",
    "\n",
    "    \n",
    "    if modLogReg[i]._pca_suc and use_PCA:\n",
    "        score_mlg = balanced_accuracy_score(true_vals[keys], modLogReg[i]._model.predict(pd.DataFrame(modLogReg[i]._pca_trans.transform(ldscaled[keys]), columns=modLogReg[i]._pca_cols)))\n",
    "        recall_mlg = recall_score(true_vals[keys], modLogReg[i]._model.predict(pd.DataFrame(modLogReg[i]._pca_trans.transform(ldscaled[keys]), columns=modLogReg[i]._pca_cols)))\n",
    "    else:\n",
    "        score_mlg = balanced_accuracy_score(true_vals[keys], modLogReg[i]._model.predict(ldscaled[keys]))\n",
    "        recall_mlg = recall_score(true_vals[keys], modLogReg[i]._model.predict(ldscaled[keys]))\n",
    "    print(\"\\tModified LogReg: {:.3f}, {:.3f}\".format(score_mlg, recall_mlg))\n",
    "    \n",
    "    \n",
    "    if modLogRegSamp[i]._pca_suc and use_PCA:\n",
    "        score_mlgs = balanced_accuracy_score(true_vals[keys], modLogRegSamp[i]._model.predict(pd.DataFrame(modLogRegSamp[i]._pca_trans.transform(ldscaled[keys]), columns=modLogRegSamp[i]._pca_cols)))\n",
    "        recall_mlgs = recall_score(true_vals[keys], modLogRegSamp[i]._model.predict(pd.DataFrame(modLogRegSamp[i]._pca_trans.transform(ldscaled[keys]), columns=modLogRegSamp[i]._pca_cols)))\n",
    "    else:\n",
    "        score_mlgs = balanced_accuracy_score(true_vals[keys], modLogRegSamp[i]._model.predict(ldscaled[keys]))\n",
    "        recall_mlgs = recall_score(true_vals[keys], modLogRegSamp[i]._model.predict(ldscaled[keys]))\n",
    "    print(\"\\tModified LogReg (SubSamp): {:.3f}, {:.3f}\".format(score_mlgs, recall_mlgs))\n",
    "\n",
    "\n",
    "\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b302a3-c46f-4973-87e9-529ff27d6d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Classifier\n",
    "eval_set = prepare_data('ClientBehaviourEvaluation.txt', keep_outliers=True, binarize_cols=False, split_structure=False)\n",
    "keys = list(true_vals.keys())\n",
    "cols = eval_set.select_dtypes(include=(\"float64\", \"int64\")).columns\n",
    "ldscaled = StandardScaler().fit_transform(eval_set.select_dtypes(include=(\"float64\", \"int64\")))\n",
    "ldscaled = pd.DataFrame(ldscaled, columns=cols)\n",
    "\n",
    "datapoint = ldscaled.sample(n=1)\n",
    "\n",
    "probs = []\n",
    "for i in logReg:\n",
    "    pred = i._model.predict_proba(datapoint)\n",
    "    probs.append(pred[:,1])\n",
    "\n",
    "print(np.asarray(probs))\n",
    "print(np.argmax(np.asarray(probs)))\n",
    "print('Recommended Action: {}'.format(keys[np.argmax(np.asarray(probs))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c571e-1a7f-48e8-ae14-82d070cc4929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
